{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMSxpJAkqYzk"
   },
   "source": [
    "# Assignment 4: Explainability\n",
    "\n",
    "*Part of the course:\n",
    "Machine Learning (code: INFOB3ML), fall 2022, Utrecht University*\n",
    "\n",
    "Total points: 10 (100%)\n",
    "\n",
    "Deadline: Friday 4 November, 23:59\n",
    "\n",
    "**Write your names and student numbers here: ___**\n",
    "\n",
    "Submit one ipynb file per pair.\n",
    "\n",
    "**Before you submit, click Kernel > Restart & Run All to make sure you submit a working version of your code!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyaViIx8WzS"
   },
   "source": [
    "## Installation\n",
    "\n",
    "For this assignment, we are going to use the following Python packages:\n",
    "\n",
    "matplotlib, pandas, statsmodels, interpret, scikit-learn, openpyxl and graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6EaC6P7RqXOh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing packages\n",
    "#!conda install python-graphviz\n",
    "%conda install python-graphviz\n",
    "#!pip install matplotlib pandas statsmodels interpret sklearn openpyxl\n",
    "# Needed for PDP\n",
    "#!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeSC0_WEpY0k"
   },
   "source": [
    "## Downloading the data\n",
    "We are going to use the combined cycle power plant dataset. This dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. We have the following features: hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V). We will train ML models to predict the net hourly electrical energy output (EP) of the plant.\n",
    "\n",
    "For a detailed description, see: [[Description](https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant)]\n",
    "\n",
    "We first need to download and prepare data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fleSmPrE7UMT"
   },
   "outputs": [],
   "source": [
    "# Download and unzip data\n",
    "!wget -c https://archive.ics.uci.edu/ml/machine-learning-databases/00294/CCPP.zip\n",
    "!unzip CCPP.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQpW5C3Sg9YA"
   },
   "source": [
    "## Loading and preprocessing the data\n",
    "We split the data into training (first 5000 instances) and validation (the subsequent 2000) and test (the last 2568) sets. We will use the training set to train a model, and validation set to optimize the model hyper-parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JycjPmn_7p41"
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# global variables\n",
    "DATA_FILENAME = 'CCPP/Folds5x2_pp.xlsx'\n",
    "FEATURE_NAMES = ['AT', 'V', 'AP', 'RH']\n",
    "LABEL_NAME = 'PE'\n",
    "# Load the data from the excel file\n",
    "def load_data():\n",
    "    def split_feature_label(data_set):\n",
    "        features = data_set[FEATURE_NAMES]\n",
    "        labels = data_set[LABEL_NAME]\n",
    "        return features, labels\n",
    "\n",
    "    data = pd.read_excel(DATA_FILENAME)\n",
    "    train_set, dev_set, test_set = data[:5000], data[5000: 7000], data[7000:]\n",
    "\n",
    "    train_features, train_labels = split_feature_label(train_set)\n",
    "    dev_features, dev_labels = split_feature_label(dev_set)\n",
    "    test_features, test_labels = split_feature_label(test_set)\n",
    "\n",
    "    return train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels\n",
    "\n",
    "\n",
    "# preprocess (by z-normalization) the data for the regression task\n",
    "# return the normalized feature sets and corresponding target variables \n",
    "def prepare_load_regression_data():\n",
    "    train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels = load_data()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(train_features)\n",
    "    train_features = pd.DataFrame(data=scaler.transform(train_features), columns=FEATURE_NAMES)\n",
    "    dev_features = pd.DataFrame(data=scaler.transform(dev_features), columns=FEATURE_NAMES)\n",
    "    test_features = pd.DataFrame(data=scaler.transform(test_features), columns=FEATURE_NAMES)\n",
    "\n",
    "    return train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QabF2JOdMTI4"
   },
   "source": [
    "## Training and Interpreting a Linear Regression Model\n",
    "\n",
    "**Q1**. (10)% Train a linear regression model (we recommend the statsmodels package) and report $R^2$ (goodness of fit) statistic. \n",
    "\n",
    "For model interpretability, provide for each feature (+ the bias variable) the following in tabular format: \n",
    "* Weight estimates\n",
    "* SE (standard error of estimates) \n",
    "* T statistics \n",
    "\n",
    "\n",
    "Further Questions regarding the linear model (answers to be included in the notebook): \n",
    "\n",
    "**Q2**. (10%) Which three features are the most important?\n",
    "\n",
    "**Q3**. (10%) How does the gas turbine energy yield (EP) change with unit (one degree C) increase of the ambient temperature given that all other feature values remain the same? (Note: Here you should consider whether you use the original or z-normalized features to train your linear model.)\n",
    "\n",
    "**Q4**. (10%) Show bar graph illustrations of the feature effects for the first two validation set instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B91BszFhMStw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.929\n",
      "Model:                            OLS   Adj. R-squared:                  0.929\n",
      "Method:                 Least Squares   F-statistic:                 1.644e+04\n",
      "Date:                Tue, 25 Oct 2022   Prob (F-statistic):               0.00\n",
      "Time:                        18:37:57   Log-Likelihood:                -14635.\n",
      "No. Observations:                5000   AIC:                         2.928e+04\n",
      "Df Residuals:                    4995   BIC:                         2.931e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        454.4443      0.064   7108.416      0.000     454.319     454.570\n",
      "AT           -14.8080      0.156    -95.152      0.000     -15.113     -14.503\n",
      "V             -2.8534      0.127    -22.543      0.000      -3.102      -2.605\n",
      "AP             0.3820      0.077      4.948      0.000       0.231       0.533\n",
      "RH            -2.4247      0.083    -29.185      0.000      -2.588      -2.262\n",
      "==============================================================================\n",
      "Omnibus:                      498.725   Durbin-Watson:                   2.030\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2485.693\n",
      "Skew:                          -0.355   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.380   Cond. No.                         4.85\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "R^2:  0.9294006278833447\n",
      "T-values:\n",
      "  const    7108.416217\n",
      "AT        -95.152274\n",
      "V         -22.543124\n",
      "AP          4.948008\n",
      "RH        -29.185187\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31617\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning:\n",
      "\n",
      "In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We recommend the statsmodels package\n",
    "import statsmodels.api as sm\n",
    "# Hint, by default this sm does not include the bias/offset term w_0\n",
    "# thus, you should add it yourself using sm.add_constant()\n",
    "\n",
    "# Linear regression\n",
    "\n",
    "train_features, train_labels, dev_features, dev_labels, test_features, test_labels = prepare_load_regression_data()\n",
    "\n",
    "X = None\n",
    "X = sm.add_constant(train_features)\n",
    "\n",
    "model = sm.OLS(train_labels, X)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "print(\"R^2: \", results.rsquared)\n",
    "print(\"T-values:\\n \", results.tvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tj6Pri4HBeO"
   },
   "source": [
    "Reflection: why would training a regression tree not work well for this dataset in terms of model interpretability? (answer in the notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7r09mMfeo2k"
   },
   "source": [
    "## Training and Interpreting an Explainable Boosting Model (Generalized Additive Model)\n",
    "**Q6**. (20%) Train a Explainable Boosting Machine (with [interpret.ml](https://github.com/interpretml/interpret/))\n",
    "\n",
    "(Note on grading: Training EBM 10%, global and local explanation visualizations - see below -  5% each)\n",
    "\n",
    "For a tutorial see: [[Tutorial](https://nbviewer.org/github/interpretml/interpret/blob/master/examples/python/notebooks/Interpretable%20Regression%20Methods.ipynb)]\n",
    "\n",
    "\n",
    "* (5%) Visualize/provide global (model-wise) feature importances for EBM as a table or figure. What are the most important two features in EBM? Are they the same as in the linear model? \n",
    "* (5%) Visualize local (instance-wise) feature importances for a development set instance of your choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-ZmqpxweoZv"
   },
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# EBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k7dAwTIfbsc"
   },
   "source": [
    "## Training and Explaining Neural Networks\n",
    "**Q7**. (20%) Train a Neural Network (using the training and validation sets): One-layer MLP (ReLU activation function + 50 hidden neurons) \n",
    "\n",
    "We recommend to use the Adam optimizer. Fine-tune the learning rate and any other hyper-parameters you find necessary. \n",
    "\n",
    "For a tutorial see: [[Tutorial](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)]\n",
    "\n",
    "Your code should report the results following the instructions below:\n",
    "\n",
    "Note on grading: training NN: 8%, answering below sub-questions 4% each.\n",
    "\n",
    "* (4%) Apply the trained neural network model on the test set and report Root Mean Square Error (RMSE) performance measure.\n",
    "\n",
    "* Analyzing factors influencing the neural network predictions. \n",
    "See the [Documentation](https://scikit-learn.org/stable/modules/partial_dependence.html) to use Partial Dependence Plot (PDP) and Independent Conditional Expectation (ICE) implementations in python.\n",
    "Use the trained one-layer MLP model to\n",
    "  * (4%) Generate and report a bivariate PDP using 'AT' (Ambient Temperature) and 'V' (Exhaust Vacuum) features (Note: not two univariate PDPs but one bivariate PDP).\n",
    "  * (4%) Generate  ICE plots for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQjg_qtCf_WD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# One-layer MLP use  learning_rate_init=0.001 to get a reasonable model, optimize other parameters by experimentation\n",
    "# an RMSE around 4.2 is reasonable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpGv6J6XlBQ4"
   },
   "source": [
    "### Generating Model-Agnostic Explanations for NN predictions\n",
    "You can check the tutorials for LIME explanations for neural networks \n",
    "[[LIME Tutorial](https://nbviewer.org/github/interpretml/interpret/blob/master/examples/python/notebooks/Explaining%20Blackbox%20Regressors.ipynb)]\n",
    "\n",
    "\n",
    "**Q8**. (10%) Provide explanations for two randomly selected test set instances using LIME for the trained NN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIo-o_lClJYQ"
   },
   "outputs": [],
   "source": [
    "# Global explanations\n",
    "import graphviz\n",
    "from interpret import show\n",
    "\n",
    "# Local explanations (LIME)\n",
    "from interpret.blackbox import LimeTabular\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
